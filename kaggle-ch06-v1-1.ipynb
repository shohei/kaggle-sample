{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f89196",
   "metadata": {
    "papermill": {
     "duration": 0.015687,
     "end_time": "2022-06-02T02:04:34.222325",
     "exception": false,
     "start_time": "2022-06-02T02:04:34.206638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggleで磨く 機械学習の実践力\n",
    "# 第6章 モデルチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840254b",
   "metadata": {
    "papermill": {
     "duration": 0.013574,
     "end_time": "2022-06-02T02:04:34.250516",
     "exception": false,
     "start_time": "2022-06-02T02:04:34.236942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.1 LightGBMのハイパーパラメータのチューニング\n",
    "## 6.1.2 ハイパーパラメータの自動チューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256d049",
   "metadata": {
    "papermill": {
     "duration": 0.013964,
     "end_time": "2022-06-02T02:04:34.279424",
     "exception": false,
     "start_time": "2022-06-02T02:04:34.265460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: ライブラリのインポート (スクリプト4-1の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59600109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:34.309684Z",
     "iopub.status.busy": "2022-06-02T02:04:34.309085Z",
     "iopub.status.idle": "2022-06-02T02:04:48.473201Z",
     "shell.execute_reply": "2022-06-02T02:04:48.471799Z"
    },
    "papermill": {
     "duration": 14.182429,
     "end_time": "2022-06-02T02:04:48.475800",
     "exception": false,
     "start_time": "2022-06-02T02:04:34.293371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_profiling==3.2.0\r\n",
      "  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.6/262.6 kB\u001b[0m \u001b[31m853.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (6.0)\r\n",
      "Requirement already satisfied: pydantic>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.8.2)\r\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (3.5.2)\r\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (3.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.21.6)\r\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (0.1.12)\r\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (2.27.1)\r\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (0.11.2)\r\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.3.5)\r\n",
      "Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (0.4.2)\r\n",
      "Collecting visions[type_image_path]==0.7.4\r\n",
      "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (4.64.0)\r\n",
      "Requirement already satisfied: joblib~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.7.3)\r\n",
      "Collecting markupsafe~=2.1.1\r\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Requirement already satisfied: phik>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (0.12.2)\r\n",
      "Requirement already satisfied: multimethod>=1.4 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling==3.2.0) (1.4)\r\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (21.4.0)\r\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (2.5)\r\n",
      "Requirement already satisfied: imagehash in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (4.2.1)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (9.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (1.4.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (4.33.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (21.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas_profiling==3.2.0) (3.0.9)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling==3.2.0) (2022.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pydantic>=1.8.1->pandas_profiling==3.2.0) (4.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas_profiling==3.2.0) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas_profiling==3.2.0) (2022.5.18.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas_profiling==3.2.0) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.24.0->pandas_profiling==3.2.0) (3.3)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.4->visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (5.1.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas_profiling==3.2.0) (1.16.0)\r\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas_profiling==3.2.0) (1.3.0)\r\n",
      "Installing collected packages: markupsafe, visions, pandas_profiling\r\n",
      "  Attempting uninstall: markupsafe\r\n",
      "    Found existing installation: MarkupSafe 2.0.1\r\n",
      "    Uninstalling MarkupSafe-2.0.1:\r\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\r\n",
      "  Attempting uninstall: visions\r\n",
      "    Found existing installation: visions 0.7.5\r\n",
      "    Uninstalling visions-0.7.5:\r\n",
      "      Successfully uninstalled visions-0.7.5\r\n",
      "  Attempting uninstall: pandas_profiling\r\n",
      "    Found existing installation: pandas-profiling 2.4.0\r\n",
      "    Uninstalling pandas-profiling-2.4.0:\r\n",
      "      Successfully uninstalled pandas-profiling-2.4.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed markupsafe-2.1.1 pandas_profiling-3.2.0 visions-0.7.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 2022/06/02追加: Kaggle notebook環境変更のため\n",
    "!pip install pandas_profiling==3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc4e0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:48.510427Z",
     "iopub.status.busy": "2022-06-02T02:04:48.510039Z",
     "iopub.status.idle": "2022-06-02T02:04:52.526517Z",
     "shell.execute_reply": "2022-06-02T02:04:52.525417Z"
    },
    "papermill": {
     "duration": 4.036383,
     "end_time": "2022-06-02T02:04:52.528763",
     "exception": false,
     "start_time": "2022-06-02T02:04:48.492380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# 分布確認\n",
    "import pandas_profiling as pdp\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 前処理\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# バリデーション\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# モデリング: lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacafd76",
   "metadata": {
    "papermill": {
     "duration": 0.015739,
     "end_time": "2022-06-02T02:04:52.561670",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.545931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: ファイルの読み込み (スクリプト4-2の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b2ec63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:52.595287Z",
     "iopub.status.busy": "2022-06-02T02:04:52.594897Z",
     "iopub.status.idle": "2022-06-02T02:04:52.613699Z",
     "shell.execute_reply": "2022-06-02T02:04:52.612903Z"
    },
    "papermill": {
     "duration": 0.038456,
     "end_time": "2022-06-02T02:04:52.615973",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.577517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da080b5",
   "metadata": {
    "papermill": {
     "duration": 0.015684,
     "end_time": "2022-06-02T02:04:52.648717",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.633033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: データセット作成 (スクリプト4-8の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b49844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:52.681693Z",
     "iopub.status.busy": "2022-06-02T02:04:52.680694Z",
     "iopub.status.idle": "2022-06-02T02:04:52.699261Z",
     "shell.execute_reply": "2022-06-02T02:04:52.698218Z"
    },
    "papermill": {
     "duration": 0.037305,
     "end_time": "2022-06-02T02:04:52.701589",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.664284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2) (891, 1) (891, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, id_train = df_train[[\"Pclass\", \"Fare\"]], \\\n",
    "                             df_train[[\"Survived\"]], \\\n",
    "                             df_train[[\"PassengerId\"]]\n",
    "print(x_train.shape, y_train.shape, id_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f0564",
   "metadata": {
    "papermill": {
     "duration": 0.015348,
     "end_time": "2022-06-02T02:04:52.733738",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.718390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-1: optunaのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f73552d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:52.766767Z",
     "iopub.status.busy": "2022-06-02T02:04:52.766059Z",
     "iopub.status.idle": "2022-06-02T02:04:53.534212Z",
     "shell.execute_reply": "2022-06-02T02:04:53.533492Z"
    },
    "papermill": {
     "duration": 0.787021,
     "end_time": "2022-06-02T02:04:53.536330",
     "exception": false,
     "start_time": "2022-06-02T02:04:52.749309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e41ff2",
   "metadata": {
    "papermill": {
     "duration": 0.015662,
     "end_time": "2022-06-02T02:04:53.569059",
     "exception": false,
     "start_time": "2022-06-02T02:04:53.553397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-2: 目的関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a343d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:53.602732Z",
     "iopub.status.busy": "2022-06-02T02:04:53.602221Z",
     "iopub.status.idle": "2022-06-02T02:04:53.612546Z",
     "shell.execute_reply": "2022-06-02T02:04:53.611901Z"
    },
    "papermill": {
     "duration": 0.02953,
     "end_time": "2022-06-02T02:04:53.614436",
     "exception": false,
     "start_time": "2022-06-02T02:04:53.584906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 探索しないハイパーパラメータ\n",
    "params_base = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するハイパーパラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,\n",
    "                 )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "    \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2c034",
   "metadata": {
    "papermill": {
     "duration": 0.015594,
     "end_time": "2022-06-02T02:04:53.646317",
     "exception": false,
     "start_time": "2022-06-02T02:04:53.630723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-3: 最適化処理（探索の実行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f101eef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:04:53.679953Z",
     "iopub.status.busy": "2022-06-02T02:04:53.679402Z",
     "iopub.status.idle": "2022-06-02T02:05:06.890170Z",
     "shell.execute_reply": "2022-06-02T02:05:06.889153Z"
    },
    "papermill": {
     "duration": 13.230219,
     "end_time": "2022-06-02T02:05:06.892324",
     "exception": false,
     "start_time": "2022-06-02T02:04:53.662105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:53,682]\u001b[0m A new study created in memory with name: no-name-ef3aec94-1d5f-4a33-bb68-d40d38ac945d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:54,344]\u001b[0m Trial 0 finished with value: 0.664478061640826 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.492522233779106, 'lambda_l2': 83.76388146302445}. Best is trial 0 with value: 0.664478061640826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:54,723]\u001b[0m Trial 1 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.567922374174008, 'lambda_l2': 0.01732652966363563}. Best is trial 1 with value: 0.6712196346745339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:55,081]\u001b[0m Trial 2 finished with value: 0.65762350134957 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102123, 'lambda_l2': 3.4482904089131434}. Best is trial 1 with value: 0.6712196346745339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:55,393]\u001b[0m Trial 3 finished with value: 0.6722302429226037 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.2799978022399009, 'lambda_l2': 0.08185645330667264}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:55,727]\u001b[0m Trial 4 finished with value: 0.668972443663298 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751797, 'lambda_l2': 0.5050346330980694}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:56,093]\u001b[0m Trial 5 finished with value: 0.6587847592743706 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:56,234]\u001b[0m Trial 6 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659076, 'lambda_l2': 1.1965765212602313}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:57,056]\u001b[0m Trial 7 finished with value: 0.6992530286862093 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:57,518]\u001b[0m Trial 8 finished with value: 0.6823363254033017 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.206714812711709, 'lambda_l2': 3.1594683442464033}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:57,769]\u001b[0m Trial 9 finished with value: 0.6362751867428285 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641542}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.994054244657564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994054244657564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16614099294894252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16614099294894252\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.994054244657564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994054244657564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16614099294894252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16614099294894252\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.994054244657564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994054244657564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16614099294894252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16614099294894252\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.994054244657564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994054244657564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16614099294894252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16614099294894252\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.994054244657564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994054244657564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16614099294894252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16614099294894252\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:58,268]\u001b[0m Trial 10 finished with value: 0.673435440336451 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0009194171614722974, 'feature_fraction': 0.5040305717020103, 'bagging_fraction': 0.994054244657564, 'lambda_l1': 0.010612397212799423, 'lambda_l2': 0.16614099294894252}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n",
      "\u001b[32m[I 2022-06-02 02:04:58,483]\u001b[0m Trial 11 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 141, 'min_data_in_leaf': 198, 'min_sum_hessian_in_leaf': 0.009951069387483545, 'feature_fraction': 0.7991399603154743, 'bagging_fraction': 0.8761275059380935, 'lambda_l1': 8.895512707730276, 'lambda_l2': 11.692356850069796}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380935\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380935\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380935\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380935\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380935, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380935\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248554\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26695313557073214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26695313557073214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248554\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26695313557073214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26695313557073214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248554\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26695313557073214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26695313557073214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248554\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26695313557073214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26695313557073214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:59,377]\u001b[0m Trial 12 finished with value: 0.6802083987194777 and parameters: {'num_leaves': 255, 'min_data_in_leaf': 18, 'min_sum_hessian_in_leaf': 0.001634914743632515, 'feature_fraction': 0.8476730378212194, 'bagging_fraction': 0.5595408581248554, 'lambda_l1': 0.09349295720311095, 'lambda_l2': 0.26695313557073214}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248554\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26695313557073214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26695313557073214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.048872499864448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.048872499864448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.048872499864448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.048872499864448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:04:59,701]\u001b[0m Trial 13 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 140, 'min_data_in_leaf': 43, 'min_sum_hessian_in_leaf': 0.0021756690901938718, 'feature_fraction': 0.9479314162009256, 'bagging_fraction': 0.9474999290561824, 'lambda_l1': 15.027486795162927, 'lambda_l2': 16.048872499864448}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.048872499864448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.048872499864448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.048872499864448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.048872499864448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.048872499864448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.048872499864448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.146751680707744, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.146751680707744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.146751680707744, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.146751680707744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.146751680707744, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.146751680707744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:00,132]\u001b[0m Trial 14 finished with value: 0.6846400100433118 and parameters: {'num_leaves': 31, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 0.0002511161117887837, 'feature_fraction': 0.7214624501496751, 'bagging_fraction': 0.8148189817022143, 'lambda_l1': 0.10302449045855189, 'lambda_l2': 7.146751680707744}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.146751680707744, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.146751680707744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.146751680707744, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.146751680707744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.212108430437809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.212108430437809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.212108430437809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.212108430437809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.212108430437809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.212108430437809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.212108430437809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.212108430437809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.212108430437809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.212108430437809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:00,548]\u001b[0m Trial 15 finished with value: 0.6745904211913878 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 46, 'min_sum_hessian_in_leaf': 0.00023305225408823253, 'feature_fraction': 0.690460596426745, 'bagging_fraction': 0.8032054077767327, 'lambda_l1': 0.026008451540619964, 'lambda_l2': 12.212108430437809}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.668068407009116, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.668068407009116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001405455693050588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001405455693050588\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.668068407009116, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.668068407009116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001405455693050588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001405455693050588\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.668068407009116, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.668068407009116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001405455693050588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001405455693050588\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:00,965]\u001b[0m Trial 16 finished with value: 0.6778858828698764 and parameters: {'num_leaves': 41, 'min_data_in_leaf': 65, 'min_sum_hessian_in_leaf': 0.0001405455693050588, 'feature_fraction': 0.816763159679514, 'bagging_fraction': 0.6677912738306708, 'lambda_l1': 0.14515159340667336, 'lambda_l2': 34.668068407009116}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.668068407009116, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.668068407009116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001405455693050588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001405455693050588\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.668068407009116, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.668068407009116\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001405455693050588, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001405455693050588\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009612\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.048375068863697315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048375068863697315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909851\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778136, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009612\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.048375068863697315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048375068863697315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909851\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778136, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009612\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.048375068863697315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048375068863697315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909851\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778136, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009612\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.048375068863697315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048375068863697315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909851\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778136, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009612\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.048375068863697315, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048375068863697315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909851\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778136, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:01,499]\u001b[0m Trial 17 finished with value: 0.6801393509509761 and parameters: {'num_leaves': 48, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.00041942600526778136, 'feature_fraction': 0.6231218216909851, 'bagging_fraction': 0.5002172961009612, 'lambda_l1': 0.03426707576896973, 'lambda_l2': 0.048375068863697315}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1840979363493544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1840979363493544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978488\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088438\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.902204589429203e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.902204589429203e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1840979363493544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1840979363493544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978488\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088438\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.902204589429203e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.902204589429203e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1840979363493544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1840979363493544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978488\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088438\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.902204589429203e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.902204589429203e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1840979363493544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1840979363493544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978488\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088438\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.902204589429203e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.902204589429203e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:02,148]\u001b[0m Trial 18 finished with value: 0.6790848032138597 and parameters: {'num_leaves': 218, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 7.902204589429203e-05, 'feature_fraction': 0.9236171148088438, 'bagging_fraction': 0.9432358972978488, 'lambda_l1': 0.1840979363493544, 'lambda_l2': 0.42463135597338963}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1840979363493544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1840979363493544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978488\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088438\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.902204589429203e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.902204589429203e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357393, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8050298850159161, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050298850159161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036466, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036466\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357393, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8050298850159161, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050298850159161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036466, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036466\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357393, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8050298850159161, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050298850159161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036466, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036466\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357393, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8050298850159161, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050298850159161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036466, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036466\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357393, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8050298850159161, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050298850159161\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036466, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036466\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:02,502]\u001b[0m Trial 19 finished with value: 0.6622308706295901 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0004165592806968668, 'feature_fraction': 0.7302924887036466, 'bagging_fraction': 0.8050298850159161, 'lambda_l1': 0.010045321756357393, 'lambda_l2': 0.0995890378098838}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.945345142341986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.945345142341986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.945345142341986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.945345142341986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.945345142341986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.945345142341986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.945345142341986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.945345142341986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:03,126]\u001b[0m Trial 20 finished with value: 0.6745904211913879 and parameters: {'num_leaves': 209, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0013845801360137001, 'feature_fraction': 0.5306298908707103, 'bagging_fraction': 0.6900582768491921, 'lambda_l1': 0.3216819410872763, 'lambda_l2': 0.945345142341986}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.945345142341986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.945345142341986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4456302415635167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4456302415635167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584702, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00874802583289836, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00874802583289836\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4456302415635167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4456302415635167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584702, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00874802583289836, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00874802583289836\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4456302415635167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4456302415635167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584702, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00874802583289836, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00874802583289836\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:03,700]\u001b[0m Trial 21 finished with value: 0.6667252526520621 and parameters: {'num_leaves': 106, 'min_data_in_leaf': 73, 'min_sum_hessian_in_leaf': 0.00874802583289836, 'feature_fraction': 0.7668244440376194, 'bagging_fraction': 0.8140984986812078, 'lambda_l1': 3.4456302415635167, 'lambda_l2': 4.156916351584702}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.4456302415635167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4456302415635167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584702, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00874802583289836, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00874802583289836\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4456302415635167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4456302415635167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584702, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00874802583289836, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00874802583289836\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.112737490486649, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.112737490486649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246624, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343572\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.112737490486649, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.112737490486649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246624, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343572\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.112737490486649, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.112737490486649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246624, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343572\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.112737490486649, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.112737490486649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246624, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343572\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:04,085]\u001b[0m Trial 22 finished with value: 0.6644152909421882 and parameters: {'num_leaves': 62, 'min_data_in_leaf': 129, 'min_sum_hessian_in_leaf': 0.004061668550970804, 'feature_fraction': 0.7482688842343572, 'bagging_fraction': 0.8886750178544316, 'lambda_l1': 2.112737490486649, 'lambda_l2': 4.554403222246624}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=2.112737490486649, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.112737490486649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246624, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343572\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.599820354752456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599820354752456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153577\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139399\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.002631280757042782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.002631280757042782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:04,345]\u001b[0m Trial 23 finished with value: 0.6453141673466826 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.002631280757042782, 'feature_fraction': 0.6773917561139399, 'bagging_fraction': 0.8221198194153577, 'lambda_l1': 8.599820354752456, 'lambda_l2': 0.7542908028826634}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.599820354752456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599820354752456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153577\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139399\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.002631280757042782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.002631280757042782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.599820354752456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599820354752456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153577\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139399\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.002631280757042782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.002631280757042782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.599820354752456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599820354752456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153577\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139399\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.002631280757042782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.002631280757042782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.599820354752456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.599820354752456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153577\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139399\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.002631280757042782, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.002631280757042782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183548, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183548\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279061\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101094, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101094\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183548, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183548\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279061\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101094, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101094\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:04,762]\u001b[0m Trial 24 finished with value: 0.6823488795430293 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 164, 'min_sum_hessian_in_leaf': 0.0007958826711101094, 'feature_fraction': 0.8193477007279061, 'bagging_fraction': 0.9137850613244668, 'lambda_l1': 0.054062737213373735, 'lambda_l2': 7.254429610183548}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183548, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183548\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279061\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101094, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101094\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183548, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183548\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279061\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101094, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101094\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183548, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183548\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279061\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101094, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101094\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8979932290605772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8979932290605772\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8979932290605772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8979932290605772\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8979932290605772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8979932290605772\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8979932290605772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8979932290605772\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8979932290605772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8979932290605772\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:05,157]\u001b[0m Trial 25 finished with value: 0.6599836796183542 and parameters: {'num_leaves': 21, 'min_data_in_leaf': 176, 'min_sum_hessian_in_leaf': 0.0007220208410542911, 'feature_fraction': 0.8979932290605772, 'bagging_fraction': 0.9096697647298414, 'lambda_l1': 0.04052688745892243, 'lambda_l2': 33.56741330161014}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354951, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354951\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7774699974900651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774699974900651\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354951, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354951\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7774699974900651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774699974900651\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354951, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354951\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7774699974900651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774699974900651\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354951, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354951\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7774699974900651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774699974900651\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:05,926]\u001b[0m Trial 26 finished with value: 0.6757140166970059 and parameters: {'num_leaves': 63, 'min_data_in_leaf': 49, 'min_sum_hessian_in_leaf': 0.00019985545118893227, 'feature_fraction': 0.8168240033302105, 'bagging_fraction': 0.7774699974900651, 'lambda_l1': 0.07242256998354951, 'lambda_l2': 6.818961945625026}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354951, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354951\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7774699974900651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774699974900651\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625026, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.132136979057582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.132136979057582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583583\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8328590281541173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328590281541173\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549294, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.132136979057582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.132136979057582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583583\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8328590281541173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328590281541173\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549294, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.132136979057582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.132136979057582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583583\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8328590281541173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328590281541173\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549294, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.132136979057582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.132136979057582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583583\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8328590281541173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328590281541173\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549294, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:06,354]\u001b[0m Trial 27 finished with value: 0.6700207143305505 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 110, 'min_sum_hessian_in_leaf': 0.0011015177430549294, 'feature_fraction': 0.8328590281541173, 'bagging_fraction': 0.9245894599408239, 'lambda_l1': 0.132136979057582, 'lambda_l2': 1.9898087013583583}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.132136979057582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.132136979057582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583583\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8328590281541173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328590281541173\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549294, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549294\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940363\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00044638503697018715, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00044638503697018715\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940363\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00044638503697018715, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00044638503697018715\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:06,577]\u001b[0m Trial 28 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 54, 'min_data_in_leaf': 169, 'min_sum_hessian_in_leaf': 0.00044638503697018715, 'feature_fraction': 0.7818076921940363, 'bagging_fraction': 0.7239926057056618, 'lambda_l1': 0.26894380562875136, 'lambda_l2': 82.43363076639685}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940363\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00044638503697018715, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00044638503697018715\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940363\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00044638503697018715, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00044638503697018715\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940363\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00044638503697018715, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00044638503697018715\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.022763155034800718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022763155034800718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-02 02:05:06,884]\u001b[0m Trial 29 finished with value: 0.6587470968551881 and parameters: {'num_leaves': 161, 'min_data_in_leaf': 196, 'min_sum_hessian_in_leaf': 8.505644215173895e-05, 'feature_fraction': 0.7116385045852216, 'bagging_fraction': 0.9850169158486759, 'lambda_l1': 0.022763155034800718, 'lambda_l2': 32.318206202200265}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.022763155034800718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022763155034800718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.022763155034800718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022763155034800718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.022763155034800718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022763155034800718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.022763155034800718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022763155034800718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a669e67",
   "metadata": {
    "papermill": {
     "duration": 0.021904,
     "end_time": "2022-06-02T02:05:06.937357",
     "exception": false,
     "start_time": "2022-06-02T02:05:06.915453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-4: 探索結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b5cb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:06.984772Z",
     "iopub.status.busy": "2022-06-02T02:05:06.984035Z",
     "iopub.status.idle": "2022-06-02T02:05:06.991803Z",
     "shell.execute_reply": "2022-06-02T02:05:06.990903Z"
    },
    "papermill": {
     "duration": 0.034119,
     "end_time": "2022-06-02T02:05:06.993606",
     "exception": false,
     "start_time": "2022-06-02T02:05:06.959487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.6993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 160,\n",
       " 'min_data_in_leaf': 28,\n",
       " 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n",
       " 'feature_fraction': 0.8015300642054637,\n",
       " 'bagging_fraction': 0.7725340032332324,\n",
       " 'lambda_l1': 0.23499322154972468,\n",
       " 'lambda_l2': 0.1646202117975735}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"acc(best)={:.4f}\".format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f07ce2",
   "metadata": {
    "papermill": {
     "duration": 0.023226,
     "end_time": "2022-06-02T02:05:07.039550",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.016324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-5: ベストなハイパーパラメータの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e2644f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.086648Z",
     "iopub.status.busy": "2022-06-02T02:05:07.085933Z",
     "iopub.status.idle": "2022-06-02T02:05:07.092764Z",
     "shell.execute_reply": "2022-06-02T02:05:07.091921Z"
    },
    "papermill": {
     "duration": 0.032877,
     "end_time": "2022-06-02T02:05:07.094767",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.061890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 160,\n",
       " 'min_data_in_leaf': 28,\n",
       " 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n",
       " 'feature_fraction': 0.8015300642054637,\n",
       " 'bagging_fraction': 0.7725340032332324,\n",
       " 'lambda_l1': 0.23499322154972468,\n",
       " 'lambda_l2': 0.1646202117975735,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': 0.02,\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_freq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29462af7",
   "metadata": {
    "papermill": {
     "duration": 0.022478,
     "end_time": "2022-06-02T02:05:07.140440",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.117962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.2 LightGBM以外のモデル利用\n",
    "## 6.2.1 scikit-learnの各種モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1f2c6",
   "metadata": {
    "papermill": {
     "duration": 0.022258,
     "end_time": "2022-06-02T02:05:07.185322",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.163064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Titanicデータを用いた例：ロジスティック回帰\n",
    "#### スクリプト6-6: ファイル読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87685c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.232867Z",
     "iopub.status.busy": "2022-06-02T02:05:07.232460Z",
     "iopub.status.idle": "2022-06-02T02:05:07.247011Z",
     "shell.execute_reply": "2022-06-02T02:05:07.246130Z"
    },
    "papermill": {
     "duration": 0.040856,
     "end_time": "2022-06-02T02:05:07.248989",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.208133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8118ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.297076Z",
     "iopub.status.busy": "2022-06-02T02:05:07.296426Z",
     "iopub.status.idle": "2022-06-02T02:05:07.304534Z",
     "shell.execute_reply": "2022-06-02T02:05:07.303673Z"
    },
    "papermill": {
     "duration": 0.034224,
     "end_time": "2022-06-02T02:05:07.306148",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.271924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age         177\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値の確認\n",
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bde07",
   "metadata": {
    "papermill": {
     "duration": 0.022345,
     "end_time": "2022-06-02T02:05:07.351387",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.329042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-7: 欠損値の補間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ba16b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.398146Z",
     "iopub.status.busy": "2022-06-02T02:05:07.397488Z",
     "iopub.status.idle": "2022-06-02T02:05:07.406275Z",
     "shell.execute_reply": "2022-06-02T02:05:07.405559Z"
    },
    "papermill": {
     "duration": 0.03437,
     "end_time": "2022-06-02T02:05:07.408093",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.373723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間：数値データ\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 欠損値補間：カテゴリ変数\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392e5df",
   "metadata": {
    "papermill": {
     "duration": 0.022032,
     "end_time": "2022-06-02T02:05:07.452806",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.430774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-8: カテゴリ変数の数値化（one-hot-encoding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7444bbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.500069Z",
     "iopub.status.busy": "2022-06-02T02:05:07.499393Z",
     "iopub.status.idle": "2022-06-02T02:05:07.510514Z",
     "shell.execute_reply": "2022-06-02T02:05:07.509436Z"
    },
    "papermill": {
     "duration": 0.037293,
     "end_time": "2022-06-02T02:05:07.512618",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.475325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(\n",
    "    ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "    columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "\n",
    "x_train = pd.concat([x_train, df_embarked], axis=1)\n",
    "x_train = x_train.drop(columns=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd46a0",
   "metadata": {
    "papermill": {
     "duration": 0.022514,
     "end_time": "2022-06-02T02:05:07.557814",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.535300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-9: 数値データの正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a53e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.604819Z",
     "iopub.status.busy": "2022-06-02T02:05:07.604397Z",
     "iopub.status.idle": "2022-06-02T02:05:07.614381Z",
     "shell.execute_reply": "2022-06-02T02:05:07.612988Z"
    },
    "papermill": {
     "duration": 0.036627,
     "end_time": "2022-06-02T02:05:07.617111",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.580484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train[\"Pclass\"] = (x_train[\"Pclass\"] -x_train[\"Pclass\"].min()) / (x_train[\"Pclass\"].max() - x_train[\"Pclass\"].min()) \n",
    "x_train[\"Age\"] = (x_train[\"Age\"] -x_train[\"Age\"].min()) / (x_train[\"Age\"].max() - x_train[\"Age\"].min()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04fe0d",
   "metadata": {
    "papermill": {
     "duration": 0.024931,
     "end_time": "2022-06-02T02:05:07.669286",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.644355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-10: 学習データと検証データの分割（ホールドアウト検証）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8847e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.728806Z",
     "iopub.status.busy": "2022-06-02T02:05:07.727680Z",
     "iopub.status.idle": "2022-06-02T02:05:07.743658Z",
     "shell.execute_reply": "2022-06-02T02:05:07.742375Z"
    },
    "papermill": {
     "duration": 0.047177,
     "end_time": "2022-06-02T02:05:07.745504",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.698327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce955f8c",
   "metadata": {
    "papermill": {
     "duration": 0.021809,
     "end_time": "2022-06-02T02:05:07.789951",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.768142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-11: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3edd8cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.837444Z",
     "iopub.status.busy": "2022-06-02T02:05:07.836387Z",
     "iopub.status.idle": "2022-06-02T02:05:07.857565Z",
     "shell.execute_reply": "2022-06-02T02:05:07.856504Z"
    },
    "papermill": {
     "duration": 0.047339,
     "end_time": "2022-06-02T02:05:07.859750",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.812411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7263\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logis = LogisticRegression()\n",
    "\n",
    "# 学習\n",
    "model_logis.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_logis.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14338e55",
   "metadata": {
    "papermill": {
     "duration": 0.021934,
     "end_time": "2022-06-02T02:05:07.904039",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.882105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-12: 確率値の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc48082d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:07.950805Z",
     "iopub.status.busy": "2022-06-02T02:05:07.949676Z",
     "iopub.status.idle": "2022-06-02T02:05:07.958249Z",
     "shell.execute_reply": "2022-06-02T02:05:07.957011Z"
    },
    "papermill": {
     "duration": 0.034042,
     "end_time": "2022-06-02T02:05:07.960172",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.926130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83621285 0.16378715]\n",
      " [0.23058311 0.76941689]\n",
      " [0.83244141 0.16755859]\n",
      " [0.32227072 0.67772928]\n",
      " [0.62569522 0.37430478]]\n"
     ]
    }
   ],
   "source": [
    "y_va_pred_proba = model_logis.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09888699",
   "metadata": {
    "papermill": {
     "duration": 0.021916,
     "end_time": "2022-06-02T02:05:08.004681",
     "exception": false,
     "start_time": "2022-06-02T02:05:07.982765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Titanicデータを用いた例：SVM\n",
    "#### スクリプト6-13: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "322a66a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:08.051026Z",
     "iopub.status.busy": "2022-06-02T02:05:08.050012Z",
     "iopub.status.idle": "2022-06-02T02:05:08.174361Z",
     "shell.execute_reply": "2022-06-02T02:05:08.173055Z"
    },
    "papermill": {
     "duration": 0.149642,
     "end_time": "2022-06-02T02:05:08.176407",
     "exception": false,
     "start_time": "2022-06-02T02:05:08.026765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7151\n",
      "[0 1 0 1 0]\n",
      "[[0.73985924 0.26014076]\n",
      " [0.28242534 0.71757466]\n",
      " [0.73986177 0.26013823]\n",
      " [0.26828214 0.73171786]\n",
      " [0.58950192 0.41049808]]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(C=1.0, random_state=123, probability=True)\n",
    "\n",
    "# 学習\n",
    "model_svm.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_svm.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "# 確率値の取得\n",
    "y_va_pred_proba = model_svm.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f5c48",
   "metadata": {
    "papermill": {
     "duration": 0.022122,
     "end_time": "2022-06-02T02:05:08.220921",
     "exception": false,
     "start_time": "2022-06-02T02:05:08.198799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.2.2 ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28216ada",
   "metadata": {
    "papermill": {
     "duration": 0.022112,
     "end_time": "2022-06-02T02:05:08.265455",
     "exception": false,
     "start_time": "2022-06-02T02:05:08.243343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### ニューラルネットワークの適用例：①全結合層のみのネットワークモデル\n",
    "#### スクリプト6-14: ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abff5bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:08.312491Z",
     "iopub.status.busy": "2022-06-02T02:05:08.311561Z",
     "iopub.status.idle": "2022-06-02T02:05:15.386905Z",
     "shell.execute_reply": "2022-06-02T02:05:15.385878Z"
    },
    "papermill": {
     "duration": 7.101344,
     "end_time": "2022-06-02T02:05:15.389245",
     "exception": false,
     "start_time": "2022-06-02T02:05:08.287901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84959226",
   "metadata": {
    "papermill": {
     "duration": 0.022427,
     "end_time": "2022-06-02T02:05:15.434604",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.412177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-15: tensorflowの再現性のためのシード指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a059f6a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:15.482412Z",
     "iopub.status.busy": "2022-06-02T02:05:15.480758Z",
     "iopub.status.idle": "2022-06-02T02:05:15.487603Z",
     "shell.execute_reply": "2022-06-02T02:05:15.486909Z"
    },
    "papermill": {
     "duration": 0.03221,
     "end_time": "2022-06-02T02:05:15.489228",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.457018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5342ca",
   "metadata": {
    "papermill": {
     "duration": 0.022052,
     "end_time": "2022-06-02T02:05:15.533822",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.511770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-16: ファイルの読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91ddd490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:15.581009Z",
     "iopub.status.busy": "2022-06-02T02:05:15.580344Z",
     "iopub.status.idle": "2022-06-02T02:05:15.592731Z",
     "shell.execute_reply": "2022-06-02T02:05:15.591826Z"
    },
    "papermill": {
     "duration": 0.038576,
     "end_time": "2022-06-02T02:05:15.595014",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.556438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a8e31",
   "metadata": {
    "papermill": {
     "duration": 0.022925,
     "end_time": "2022-06-02T02:05:15.640944",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.618019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-17: 数値データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b11c6962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:15.687736Z",
     "iopub.status.busy": "2022-06-02T02:05:15.687121Z",
     "iopub.status.idle": "2022-06-02T02:05:15.694399Z",
     "shell.execute_reply": "2022-06-02T02:05:15.693824Z"
    },
    "papermill": {
     "duration": 0.032494,
     "end_time": "2022-06-02T02:05:15.695941",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.663447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7887e",
   "metadata": {
    "papermill": {
     "duration": 0.022243,
     "end_time": "2022-06-02T02:05:15.741695",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.719452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-18: カテゴリ変数の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3648b99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:15.788785Z",
     "iopub.status.busy": "2022-06-02T02:05:15.788165Z",
     "iopub.status.idle": "2022-06-02T02:05:15.799533Z",
     "shell.execute_reply": "2022-06-02T02:05:15.798887Z"
    },
    "papermill": {
     "duration": 0.037429,
     "end_time": "2022-06-02T02:05:15.801599",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.764170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])\n",
    "\n",
    "# one-hot-encoding\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "                           columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "x_train = pd.concat([x_train.drop(columns=[\"Embarked\"]), \n",
    "                     df_embarked], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24375dd4",
   "metadata": {
    "papermill": {
     "duration": 0.023493,
     "end_time": "2022-06-02T02:05:15.849075",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.825582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-19: 学習データと検証データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29ec6bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:15.897476Z",
     "iopub.status.busy": "2022-06-02T02:05:15.896935Z",
     "iopub.status.idle": "2022-06-02T02:05:15.909426Z",
     "shell.execute_reply": "2022-06-02T02:05:15.908188Z"
    },
    "papermill": {
     "duration": 0.039687,
     "end_time": "2022-06-02T02:05:15.912120",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.872433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4905ba7",
   "metadata": {
    "papermill": {
     "duration": 0.022651,
     "end_time": "2022-06-02T02:05:15.959046",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.936395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-20: モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da15e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:16.007015Z",
     "iopub.status.busy": "2022-06-02T02:05:16.006447Z",
     "iopub.status.idle": "2022-06-02T02:05:16.204988Z",
     "shell.execute_reply": "2022-06-02T02:05:16.201994Z"
    },
    "papermill": {
     "duration": 0.225535,
     "end_time": "2022-06-02T02:05:16.207504",
     "exception": false,
     "start_time": "2022-06-02T02:05:15.981969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 331\n",
      "Trainable params: 281\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 02:05:16.064511: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    input_num = Input(shape=(5,))\n",
    "    x_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.3)(x_num)\n",
    "    x_num = Dense(10, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.2)(x_num)\n",
    "    x_num = Dense(5, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.1)(x_num)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x_num)\n",
    "\n",
    "    model = Model(inputs=input_num,\n",
    "                  outputs=out,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1e5a0",
   "metadata": {
    "papermill": {
     "duration": 0.0227,
     "end_time": "2022-06-02T02:05:16.255265",
     "exception": false,
     "start_time": "2022-06-02T02:05:16.232565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-21: モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e7fa3b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:16.304245Z",
     "iopub.status.busy": "2022-06-02T02:05:16.303874Z",
     "iopub.status.idle": "2022-06-02T02:05:23.963775Z",
     "shell.execute_reply": "2022-06-02T02:05:23.962821Z"
    },
    "papermill": {
     "duration": 7.687406,
     "end_time": "2022-06-02T02:05:23.966306",
     "exception": false,
     "start_time": "2022-06-02T02:05:16.278900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 02:05:17.163928: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "89/89 [==============================] - 2s 7ms/step - loss: 0.6693 - binary_crossentropy: 0.6693 - val_loss: 0.6570 - val_binary_crossentropy: 0.6570\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65698, saving model to model_keras.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6714 - binary_crossentropy: 0.6714 - val_loss: 0.6354 - val_binary_crossentropy: 0.6354\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65698 to 0.63545, saving model to model_keras.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6606 - binary_crossentropy: 0.6606 - val_loss: 0.6215 - val_binary_crossentropy: 0.6215\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63545 to 0.62146, saving model to model_keras.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6462 - binary_crossentropy: 0.6462 - val_loss: 0.6120 - val_binary_crossentropy: 0.6120\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62146 to 0.61204, saving model to model_keras.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_crossentropy: 0.6340 - val_loss: 0.5996 - val_binary_crossentropy: 0.5996\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61204 to 0.59962, saving model to model_keras.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_crossentropy: 0.6301 - val_loss: 0.5918 - val_binary_crossentropy: 0.5918\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.59962 to 0.59179, saving model to model_keras.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6344 - binary_crossentropy: 0.6344 - val_loss: 0.5820 - val_binary_crossentropy: 0.5820\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59179 to 0.58201, saving model to model_keras.h5\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6272 - binary_crossentropy: 0.6272 - val_loss: 0.5814 - val_binary_crossentropy: 0.5814\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.58201 to 0.58139, saving model to model_keras.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6364 - binary_crossentropy: 0.6364 - val_loss: 0.5772 - val_binary_crossentropy: 0.5772\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58139 to 0.57725, saving model to model_keras.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6193 - binary_crossentropy: 0.6193 - val_loss: 0.5760 - val_binary_crossentropy: 0.5760\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.57725 to 0.57602, saving model to model_keras.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6218 - binary_crossentropy: 0.6218 - val_loss: 0.5736 - val_binary_crossentropy: 0.5736\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.57602 to 0.57365, saving model to model_keras.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_crossentropy: 0.6326 - val_loss: 0.5779 - val_binary_crossentropy: 0.5779\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57365\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6317 - binary_crossentropy: 0.6317 - val_loss: 0.5784 - val_binary_crossentropy: 0.5784\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57365\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_crossentropy: 0.6136 - val_loss: 0.5761 - val_binary_crossentropy: 0.5761\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.57365\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6184 - binary_crossentropy: 0.6184 - val_loss: 0.5750 - val_binary_crossentropy: 0.5750\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57365\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_crossentropy: 0.6100 - val_loss: 0.5756 - val_binary_crossentropy: 0.5756\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57365\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6286 - binary_crossentropy: 0.6286 - val_loss: 0.5752 - val_binary_crossentropy: 0.5752\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57365\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_crossentropy: 0.6174 - val_loss: 0.5747 - val_binary_crossentropy: 0.5747\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57365\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_crossentropy: 0.6118 - val_loss: 0.5746 - val_binary_crossentropy: 0.5746\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57365\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6275 - binary_crossentropy: 0.6275 - val_loss: 0.5745 - val_binary_crossentropy: 0.5745\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.57365\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6146 - binary_crossentropy: 0.6146 - val_loss: 0.5747 - val_binary_crossentropy: 0.5747\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.57365\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 00021: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee3c3a7cd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(seed=123)\n",
    "model = create_model()\n",
    "model.fit(x=x_tr,\n",
    "          y=y_tr,\n",
    "          validation_data=(x_va, y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d48e2",
   "metadata": {
    "papermill": {
     "duration": 0.029105,
     "end_time": "2022-06-02T02:05:24.024901",
     "exception": false,
     "start_time": "2022-06-02T02:05:23.995796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-22: モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "725f0524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:24.086120Z",
     "iopub.status.busy": "2022-06-02T02:05:24.085286Z",
     "iopub.status.idle": "2022-06-02T02:05:28.822621Z",
     "shell.execute_reply": "2022-06-02T02:05:28.821777Z"
    },
    "papermill": {
     "duration": 4.770139,
     "end_time": "2022-06-02T02:05:28.824657",
     "exception": false,
     "start_time": "2022-06-02T02:05:24.054518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n",
      "accuracy: 0.7151\n"
     ]
    }
   ],
   "source": [
    "y_va_pred = model.predict(x_va, batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459fa48",
   "metadata": {
    "papermill": {
     "duration": 0.0286,
     "end_time": "2022-06-02T02:05:28.882436",
     "exception": false,
     "start_time": "2022-06-02T02:05:28.853836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ニューラルネットワークの適用例：②埋め込み層ありのネットワークモデル\n",
    "#### スクリプト6-23: ファイルの読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b118157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:28.943528Z",
     "iopub.status.busy": "2022-06-02T02:05:28.942389Z",
     "iopub.status.idle": "2022-06-02T02:05:28.956554Z",
     "shell.execute_reply": "2022-06-02T02:05:28.955880Z"
    },
    "papermill": {
     "duration": 0.04684,
     "end_time": "2022-06-02T02:05:28.958566",
     "exception": false,
     "start_time": "2022-06-02T02:05:28.911726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Cabin\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e39576",
   "metadata": {
    "papermill": {
     "duration": 0.028955,
     "end_time": "2022-06-02T02:05:29.017393",
     "exception": false,
     "start_time": "2022-06-02T02:05:28.988438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-24: 数値データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64755265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:29.077978Z",
     "iopub.status.busy": "2022-06-02T02:05:29.077064Z",
     "iopub.status.idle": "2022-06-02T02:05:29.085888Z",
     "shell.execute_reply": "2022-06-02T02:05:29.085189Z"
    },
    "papermill": {
     "duration": 0.041017,
     "end_time": "2022-06-02T02:05:29.087610",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.046593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058ac58",
   "metadata": {
    "papermill": {
     "duration": 0.028761,
     "end_time": "2022-06-02T02:05:29.145509",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.116748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-25: カテゴリ変数の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83fcc9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:29.205147Z",
     "iopub.status.busy": "2022-06-02T02:05:29.204083Z",
     "iopub.status.idle": "2022-06-02T02:05:29.214888Z",
     "shell.execute_reply": "2022-06-02T02:05:29.213440Z"
    },
    "papermill": {
     "duration": 0.042569,
     "end_time": "2022-06-02T02:05:29.216795",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.174226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A10' 'A14' 'A16' 'A19' 'A20' 'A23' 'A24' 'A26' 'A31' 'A32' 'A34' 'A36'\n",
      " 'A5' 'A6' 'A7' 'B101' 'B102' 'B18' 'B19' 'B20' 'B22' 'B28' 'B3' 'B30'\n",
      " 'B35' 'B37' 'B38' 'B39' 'B4' 'B41' 'B42' 'B49' 'B5' 'B50' 'B51 B53 B55'\n",
      " 'B57 B59 B63 B66' 'B58 B60' 'B69' 'B71' 'B73' 'B77' 'B78' 'B79' 'B80'\n",
      " 'B82 B84' 'B86' 'B94' 'B96 B98' 'C101' 'C103' 'C104' 'C106' 'C110' 'C111'\n",
      " 'C118' 'C123' 'C124' 'C125' 'C126' 'C128' 'C148' 'C2' 'C22 C26'\n",
      " 'C23 C25 C27' 'C30' 'C32' 'C45' 'C46' 'C47' 'C49' 'C50' 'C52' 'C54'\n",
      " 'C62 C64' 'C65' 'C68' 'C7' 'C70' 'C78' 'C82' 'C83' 'C85' 'C86' 'C87'\n",
      " 'C90' 'C91' 'C92' 'C93' 'C95' 'C99' 'D' 'D10 D12' 'D11' 'D15' 'D17' 'D19'\n",
      " 'D20' 'D21' 'D26' 'D28' 'D30' 'D33' 'D35' 'D36' 'D37' 'D45' 'D46' 'D47'\n",
      " 'D48' 'D49' 'D50' 'D56' 'D6' 'D7' 'D9' 'E10' 'E101' 'E12' 'E121' 'E17'\n",
      " 'E24' 'E25' 'E31' 'E33' 'E34' 'E36' 'E38' 'E40' 'E44' 'E46' 'E49' 'E50'\n",
      " 'E58' 'E63' 'E67' 'E68' 'E77' 'E8' 'F E69' 'F G63' 'F G73' 'F2' 'F33'\n",
      " 'F38' 'F4' 'G6' 'None' 'T']\n",
      "count: 148\n"
     ]
    }
   ],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Cabin\"] = x_train[\"Cabin\"].fillna(\"None\")\n",
    "\n",
    "# label-encoding\n",
    "le = LabelEncoder()\n",
    "le.fit(x_train[[\"Cabin\"]])\n",
    "x_train[\"Cabin\"] = le.transform(x_train[\"Cabin\"])\n",
    "\n",
    "print(le.classes_)\n",
    "print(\"count:\", len(le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70f6cb",
   "metadata": {
    "papermill": {
     "duration": 0.028665,
     "end_time": "2022-06-02T02:05:29.274706",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.246041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-26: 学習データと検証データの分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e32026b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:29.334286Z",
     "iopub.status.busy": "2022-06-02T02:05:29.333335Z",
     "iopub.status.idle": "2022-06-02T02:05:29.349934Z",
     "shell.execute_reply": "2022-06-02T02:05:29.349179Z"
    },
    "papermill": {
     "duration": 0.048535,
     "end_time": "2022-06-02T02:05:29.352034",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.303499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2) (179, 2) (712, 1) (179, 1) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_num, x_train_cat = x_train[[\"Pclass\", \"Age\"]], x_train[[\"Cabin\"]]\n",
    "\n",
    "x_num_tr, x_num_va, x_cat_tr, x_cat_va, y_tr, y_va = \\\n",
    "   train_test_split(x_train_num, x_train_cat, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_num_tr.shape, x_num_va.shape, x_cat_tr.shape, x_cat_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867b38a",
   "metadata": {
    "papermill": {
     "duration": 0.029022,
     "end_time": "2022-06-02T02:05:29.410714",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.381692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-27: モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed851e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:29.470408Z",
     "iopub.status.busy": "2022-06-02T02:05:29.469880Z",
     "iopub.status.idle": "2022-06-02T02:05:29.584869Z",
     "shell.execute_reply": "2022-06-02T02:05:29.583539Z"
    },
    "papermill": {
     "duration": 0.147672,
     "end_time": "2022-06-02T02:05:29.587221",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.439549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None,)              0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10)           40          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 74)           10952       tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 10)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 74)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           110         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 74)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           dense_9[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 50)           4250        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50)           200         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 20)           1020        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 20)           80          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20)           0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            21          dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,703\n",
      "Trainable params: 16,543\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model_embedding():\n",
    "    ################# num\n",
    "    input_num = Input(shape=(2,))\n",
    "    layer_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    layer_num = BatchNormalization()(layer_num)\n",
    "    layer_num = Dropout(0.2)(layer_num)\n",
    "    layer_num = Dense(10, activation=\"relu\")(layer_num)\n",
    "\n",
    "    ################# cat\n",
    "    input_cat = Input(shape=(1,))\n",
    "    layer_cat = input_cat[:, 0]\n",
    "    layer_cat = Embedding(input_dim=148, output_dim=74)(layer_cat)\n",
    "    layer_cat = Dropout(0.2)(layer_cat)\n",
    "    layer_cat = Flatten()(layer_cat)\n",
    "\n",
    "    ################# concat\n",
    "    hidden_layer = Concatenate()([layer_num, layer_cat])\n",
    "    hidden_layer = Dense(50, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    hidden_layer = Dense(20, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    output_layer = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    model = Model(inputs=[input_num, input_cat],\n",
    "                  outputs=output_layer,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model_embedding()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fde78",
   "metadata": {
    "papermill": {
     "duration": 0.036977,
     "end_time": "2022-06-02T02:05:29.655903",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.618926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-28: モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e35f1b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:29.734947Z",
     "iopub.status.busy": "2022-06-02T02:05:29.734294Z",
     "iopub.status.idle": "2022-06-02T02:05:36.326648Z",
     "shell.execute_reply": "2022-06-02T02:05:36.325603Z"
    },
    "papermill": {
     "duration": 6.634108,
     "end_time": "2022-06-02T02:05:36.328725",
     "exception": false,
     "start_time": "2022-06-02T02:05:29.694617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "89/89 [==============================] - 2s 6ms/step - loss: 0.7839 - binary_crossentropy: 0.7839 - val_loss: 0.7185 - val_binary_crossentropy: 0.7185\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71853, saving model to model_keras_embedding.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6714 - binary_crossentropy: 0.6714 - val_loss: 0.7027 - val_binary_crossentropy: 0.7027\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71853 to 0.70270, saving model to model_keras_embedding.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6603 - binary_crossentropy: 0.6603 - val_loss: 0.6851 - val_binary_crossentropy: 0.6851\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70270 to 0.68515, saving model to model_keras_embedding.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6500 - binary_crossentropy: 0.6500 - val_loss: 0.6301 - val_binary_crossentropy: 0.6301\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68515 to 0.63009, saving model to model_keras_embedding.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6397 - binary_crossentropy: 0.6397 - val_loss: 0.6263 - val_binary_crossentropy: 0.6263\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.63009 to 0.62630, saving model to model_keras_embedding.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6183 - binary_crossentropy: 0.6183 - val_loss: 0.6088 - val_binary_crossentropy: 0.6088\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62630 to 0.60878, saving model to model_keras_embedding.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5768 - binary_crossentropy: 0.5768 - val_loss: 0.6021 - val_binary_crossentropy: 0.6021\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60878 to 0.60214, saving model to model_keras_embedding.h5\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5753 - binary_crossentropy: 0.5753 - val_loss: 0.6158 - val_binary_crossentropy: 0.6158\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60214\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5917 - binary_crossentropy: 0.5917 - val_loss: 0.6425 - val_binary_crossentropy: 0.6425\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.60214\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5576 - binary_crossentropy: 0.5576 - val_loss: 0.6347 - val_binary_crossentropy: 0.6347\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60214\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5527 - binary_crossentropy: 0.5527 - val_loss: 0.6122 - val_binary_crossentropy: 0.6122\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.60214\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5586 - binary_crossentropy: 0.5586 - val_loss: 0.6718 - val_binary_crossentropy: 0.6718\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60214\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5775 - binary_crossentropy: 0.5775 - val_loss: 0.6696 - val_binary_crossentropy: 0.6696\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60214\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5700 - binary_crossentropy: 0.5700 - val_loss: 0.6680 - val_binary_crossentropy: 0.6680\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60214\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5395 - binary_crossentropy: 0.5395 - val_loss: 0.6657 - val_binary_crossentropy: 0.6657\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60214\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5545 - binary_crossentropy: 0.5545 - val_loss: 0.6665 - val_binary_crossentropy: 0.6665\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60214\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5586 - binary_crossentropy: 0.5586 - val_loss: 0.6672 - val_binary_crossentropy: 0.6672\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee17fd8190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(seed=123)\n",
    "model = create_model_embedding()\n",
    "model.fit(x=[x_num_tr, x_cat_tr],\n",
    "          y=y_tr,\n",
    "          validation_data=([x_num_va, x_cat_va], y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras_embedding.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b275a",
   "metadata": {
    "papermill": {
     "duration": 0.03438,
     "end_time": "2022-06-02T02:05:36.398061",
     "exception": false,
     "start_time": "2022-06-02T02:05:36.363681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-29: モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0ed8fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:36.469507Z",
     "iopub.status.busy": "2022-06-02T02:05:36.468669Z",
     "iopub.status.idle": "2022-06-02T02:05:36.720463Z",
     "shell.execute_reply": "2022-06-02T02:05:36.719118Z"
    },
    "papermill": {
     "duration": 0.289838,
     "end_time": "2022-06-02T02:05:36.722336",
     "exception": false,
     "start_time": "2022-06-02T02:05:36.432498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n",
      "accuracy: 0.7151\n"
     ]
    }
   ],
   "source": [
    "y_va_pred = model.predict([x_num_va, x_cat_va], batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260467a",
   "metadata": {
    "papermill": {
     "duration": 0.035256,
     "end_time": "2022-06-02T02:05:36.793180",
     "exception": false,
     "start_time": "2022-06-02T02:05:36.757924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.3 アンサンブル\n",
    "## 6.3.1 単純平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c46608",
   "metadata": {
    "papermill": {
     "duration": 0.03474,
     "end_time": "2022-06-02T02:05:36.862890",
     "exception": false,
     "start_time": "2022-06-02T02:05:36.828150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-30: 3モデルの予測値を持つデータフレームを乱数で作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75fa4454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:36.935506Z",
     "iopub.status.busy": "2022-06-02T02:05:36.934374Z",
     "iopub.status.idle": "2022-06-02T02:05:36.963911Z",
     "shell.execute_reply": "2022-06-02T02:05:36.963258Z"
    },
    "papermill": {
     "duration": 0.06756,
     "end_time": "2022-06-02T02:05:36.965779",
     "exception": false,
     "start_time": "2022-06-02T02:05:36.898219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3\n",
       "0     1  0.683821  0.874443  0.859939\n",
       "1     0  0.540691  0.113419  0.197144\n",
       "2     0  0.310541  0.334798  0.599304\n",
       "3     0  0.043486  0.170622  0.378528\n",
       "4     0  0.550847  0.354703  0.598860"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "df = pd.DataFrame({\n",
    "    \"true\": [0]*700 + [1]*300,\n",
    "    \"pred1\":np.arange(1000) + np.random.rand(1000)*1200,\n",
    "    \"pred2\":np.arange(1000) + np.random.rand(1000)*1000,\n",
    "    \"pred3\":np.arange(1000) + np.random.rand(1000)*800,\n",
    "})\n",
    "df[\"pred1\"] = np.clip(df[\"pred1\"]/df[\"pred1\"].max(), 0, 1)\n",
    "df[\"pred2\"] = np.clip(df[\"pred2\"]/df[\"pred2\"].max(), 0, 1)\n",
    "df[\"pred3\"] = np.clip(df[\"pred3\"]/df[\"pred3\"].max(), 0, 1)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.8, stratify=df[\"true\"], random_state=123)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ba302",
   "metadata": {
    "papermill": {
     "duration": 0.034222,
     "end_time": "2022-06-02T02:05:37.035170",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.000948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-31: 単純平均によるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34896331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.106184Z",
     "iopub.status.busy": "2022-06-02T02:05:37.105581Z",
     "iopub.status.idle": "2022-06-02T02:05:37.117350Z",
     "shell.execute_reply": "2022-06-02T02:05:37.116746Z"
    },
    "papermill": {
     "duration": 0.049472,
     "end_time": "2022-06-02T02:05:37.119019",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.069547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.806068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.283752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.414881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.197545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.501470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble1\n",
       "0     1  0.683821  0.874443  0.859939        0.806068\n",
       "1     0  0.540691  0.113419  0.197144        0.283752\n",
       "2     0  0.310541  0.334798  0.599304        0.414881\n",
       "3     0  0.043486  0.170622  0.378528        0.197545\n",
       "4     0  0.550847  0.354703  0.598860        0.501470"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"pred_ensemble1\"] = (df_train[\"pred1\"] + df_train[\"pred2\"] + df_train[\"pred3\"]) / 3\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9405b",
   "metadata": {
    "papermill": {
     "duration": 0.034185,
     "end_time": "2022-06-02T02:05:37.187630",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.153445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-32: アンサンブル用の精度評価関数と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "265000b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.259412Z",
     "iopub.status.busy": "2022-06-02T02:05:37.258693Z",
     "iopub.status.idle": "2022-06-02T02:05:37.270501Z",
     "shell.execute_reply": "2022-06-02T02:05:37.269148Z"
    },
    "papermill": {
     "duration": 0.049438,
     "end_time": "2022-06-02T02:05:37.272449",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.223011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9585\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ensemble(input_df, col_pred):\n",
    "    print(\"[auc] model1:{:.4f}, model2:{:.4f}, model3:{:.4f} -> ensemble:{:.4f}\".format(\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred1\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred2\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred3\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[col_pred]),\n",
    "    ))\n",
    "\n",
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe6812",
   "metadata": {
    "papermill": {
     "duration": 0.034781,
     "end_time": "2022-06-02T02:05:37.342872",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.308091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-33: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fe07559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.414227Z",
     "iopub.status.busy": "2022-06-02T02:05:37.413422Z",
     "iopub.status.idle": "2022-06-02T02:05:37.426088Z",
     "shell.execute_reply": "2022-06-02T02:05:37.424765Z"
    },
    "papermill": {
     "duration": 0.050255,
     "end_time": "2022-06-02T02:05:37.427948",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.377693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9396\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble1\"] = (df_test[\"pred1\"] + df_test[\"pred2\"] + df_test[\"pred3\"]) / 3\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd3d5a",
   "metadata": {
    "papermill": {
     "duration": 0.035094,
     "end_time": "2022-06-02T02:05:37.498140",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.463046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.3.2 重み付き平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce1e11",
   "metadata": {
    "papermill": {
     "duration": 0.034657,
     "end_time": "2022-06-02T02:05:37.567512",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.532855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-34: 重み付き平均によるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "842ba6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.639175Z",
     "iopub.status.busy": "2022-06-02T02:05:37.638562Z",
     "iopub.status.idle": "2022-06-02T02:05:37.653120Z",
     "shell.execute_reply": "2022-06-02T02:05:37.652193Z"
    },
    "papermill": {
     "duration": 0.052975,
     "end_time": "2022-06-02T02:05:37.655137",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.602162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.3 0.4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.811455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.275091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.433324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.215643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.511209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble2\n",
       "0     1  0.683821  0.874443  0.859939        0.811455\n",
       "1     0  0.540691  0.113419  0.197144        0.275091\n",
       "2     0  0.310541  0.334798  0.599304        0.433324\n",
       "3     0  0.043486  0.170622  0.378528        0.215643\n",
       "4     0  0.550847  0.354703  0.598860        0.511209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = [0.3, 0.3, 0.4]\n",
    "weight = weight / np.sum(weight)\n",
    "print(weight)\n",
    "\n",
    "df_train[\"pred_ensemble2\"] = df_train[\"pred1\"] * weight[0] + \\\n",
    "                             df_train[\"pred2\"] * weight[1] + \\\n",
    "                             df_train[\"pred3\"] * weight[2]\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble2\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1008c",
   "metadata": {
    "papermill": {
     "duration": 0.035027,
     "end_time": "2022-06-02T02:05:37.725818",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.690791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-35: アンサンブルの精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6756139a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.797784Z",
     "iopub.status.busy": "2022-06-02T02:05:37.797396Z",
     "iopub.status.idle": "2022-06-02T02:05:37.809315Z",
     "shell.execute_reply": "2022-06-02T02:05:37.807930Z"
    },
    "papermill": {
     "duration": 0.049966,
     "end_time": "2022-06-02T02:05:37.811248",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.761282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9614\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18eefa",
   "metadata": {
    "papermill": {
     "duration": 0.035015,
     "end_time": "2022-06-02T02:05:37.882342",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.847327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-36: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4078d19e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:37.954217Z",
     "iopub.status.busy": "2022-06-02T02:05:37.953187Z",
     "iopub.status.idle": "2022-06-02T02:05:37.965603Z",
     "shell.execute_reply": "2022-06-02T02:05:37.964718Z"
    },
    "papermill": {
     "duration": 0.051258,
     "end_time": "2022-06-02T02:05:37.968471",
     "exception": false,
     "start_time": "2022-06-02T02:05:37.917213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9420\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble2\"] = df_test[\"pred1\"] * weight[0] + \\\n",
    "                            df_test[\"pred2\"] * weight[1] + \\\n",
    "                            df_test[\"pred3\"] * weight[2]\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed9d95",
   "metadata": {
    "papermill": {
     "duration": 0.036137,
     "end_time": "2022-06-02T02:05:38.040838",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.004701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.3.3 スタッキング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f483b",
   "metadata": {
    "papermill": {
     "duration": 0.035541,
     "end_time": "2022-06-02T02:05:38.113298",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.077757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-37: スタッキングによるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62f23f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:38.187191Z",
     "iopub.status.busy": "2022-06-02T02:05:38.186380Z",
     "iopub.status.idle": "2022-06-02T02:05:38.232929Z",
     "shell.execute_reply": "2022-06-02T02:05:38.232274Z"
    },
    "papermill": {
     "duration": 0.085704,
     "end_time": "2022-06-02T02:05:38.235067",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.149363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.745020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.206734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.303498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble3\n",
       "0     1  0.683821  0.874443  0.859939        0.745020\n",
       "1     0  0.540691  0.113419  0.197144        0.000000\n",
       "2     0  0.310541  0.334798  0.599304        0.206734\n",
       "3     0  0.043486  0.170622  0.378528        0.000000\n",
       "4     0  0.550847  0.354703  0.598860        0.303498"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x, y = df_train[[\"pred1\", \"pred2\", \"pred3\"]], df_train[[\"true\"]]\n",
    "oof = np.zeros(len(x))\n",
    "models = []\n",
    "\n",
    "cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x, y))\n",
    "for nfold in np.arange(5):\n",
    "    # 学習データと検証データの分離\n",
    "    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "    x_tr, y_tr = x.loc[idx_tr, :], y.loc[idx_tr, :]\n",
    "    x_va, y_va = x.loc[idx_va, :], y.loc[idx_va, :]\n",
    "    \n",
    "    # モデル学習\n",
    "    model = Lasso(alpha=0.01)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    models.append(model)\n",
    "    \n",
    "    # 検証データの予測値算出\n",
    "    y_va_pred = model.predict(x_va)\n",
    "    oof[idx_va] = y_va_pred\n",
    "    \n",
    "df_train[\"pred_ensemble3\"] = oof\n",
    "df_train[\"pred_ensemble3\"] = df_train[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble3\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea38abc",
   "metadata": {
    "papermill": {
     "duration": 0.03491,
     "end_time": "2022-06-02T02:05:38.305273",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.270363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-38: アンサンブルの精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e23347ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:38.377081Z",
     "iopub.status.busy": "2022-06-02T02:05:38.376639Z",
     "iopub.status.idle": "2022-06-02T02:05:38.387661Z",
     "shell.execute_reply": "2022-06-02T02:05:38.386384Z"
    },
    "papermill": {
     "duration": 0.050017,
     "end_time": "2022-06-02T02:05:38.390098",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.340081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9577\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcb319",
   "metadata": {
    "papermill": {
     "duration": 0.035521,
     "end_time": "2022-06-02T02:05:38.461972",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.426451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-39: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10eed447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T02:05:38.534702Z",
     "iopub.status.busy": "2022-06-02T02:05:38.533803Z",
     "iopub.status.idle": "2022-06-02T02:05:38.558316Z",
     "shell.execute_reply": "2022-06-02T02:05:38.557638Z"
    },
    "papermill": {
     "duration": 0.062905,
     "end_time": "2022-06-02T02:05:38.560182",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.497277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9437\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble3\"] = 0\n",
    "for model in models:\n",
    "    df_test[\"pred_ensemble3\"] += model.predict(df_test[[\"pred1\", \"pred2\", \"pred3\"]]) / len(models)\n",
    "df_test[\"pred_ensemble3\"] = df_test[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de77e7e",
   "metadata": {
    "papermill": {
     "duration": 0.03633,
     "end_time": "2022-06-02T02:05:38.632109",
     "exception": false,
     "start_time": "2022-06-02T02:05:38.595779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.658962,
   "end_time": "2022-06-02T02:05:41.753101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-02T02:04:25.094139",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
